{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB_LxRzSbrBl"
   },
   "source": [
    "## Домашнее задание №4\n",
    "\n",
    "В качестве домашнего задания предлагаются следующие задачи:\n",
    "\n",
    "1) Реализовать метод аугментации текстовых данных на основе дистрибутивных векторных представлений, который можно применить в перечисленных ниже задачах (на выбор) и проанализировать итоговое качество с/без аугментации.\n",
    "\n",
    "2) Решить задачу регрессии с использованием текстовых признаков на англоязычном датасете [Medium Stories](https://www.kaggle.com/harrisonjansma/medium-stories).\n",
    "\n",
    "3) Решить задачу детекции парафразов.\n",
    "\n",
    "4) Использовать методы для нахождения оптимальных гиперпараметров модели.\n",
    "\n",
    "5) Использовать кросс-валидацию и/или методы семплирования данных.\n",
    "\n",
    "Это домашнее задание является \"конструктором\": вы можете выполнить интересующие вас блоки или получить больше 10 баллов.\n",
    "\n",
    "Если качество моделей не повысилось, но попытка реализована верно, вы все равно получаете баллы (например, при конструировании собственных текстовых признаков). \n",
    "\n",
    "Дедлайн: **18 октября 23:59**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJntJKWGe3Ux"
   },
   "source": [
    "### Блок 1: Аугментация с заменой слов на основе ```word2vec``` (2 балла)\n",
    "\n",
    "* Можно использовать библиотеку ```gensim``` и модели [rusvectores](https://rusvectores.org/ru/models/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "mR7tuRTwf_cz",
    "outputId": "29ed11c5-8694-4eab-d38b-c3602fa776a1"
   },
   "outputs": [],
   "source": [
    "# !wget -c http://vectors.nlpl.eu/repository/20/180.zip\n",
    "# !unzip 180.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "P64Ge3mLZ4zn",
    "outputId": "0a2756a1-2613-40e1-c09a-f31a940a9a25"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# model_file = 'araneum_none_fasttextcbow_300_5_2018.model'\n",
    "\n",
    "# model = KeyedVectors.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"бабушка_NOUN\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "import string\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def my_preprocess(text: str):\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\n\", \" \").replace('/', ' ')\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_text = list(tokenize(text))\n",
    "    lemm = [morph.parse(i.text)[0].normal_form for i in tokenized_text]\n",
    "    words = [i for i in lemm if i not in stop]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdUdpIiDhpFA"
   },
   "source": [
    "Напишите функцию, которая заменяет слова во входном предложении их ближайшими семантическими ассоциатами (1 балл)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9PcdwIL0hHBv"
   },
   "outputs": [],
   "source": [
    "def augment_word2vec(sentence, model=model):\n",
    "    sentence = str(sentence)\n",
    "    res = []\n",
    "    for word in sentence.split():\n",
    "        normal_form = morph.parse(word)[0]\n",
    "        word_POS = normal_form.normal_form + \"_\" + str(normal_form.tag.POS)\n",
    "        if word_POS in model: \n",
    "            res.append(model.most_similar(positive=[word_POS], topn=1)[0][0].split(\"_\"))\n",
    "    res = [i[0] for i in res]\n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мама вымывать окошко'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "sent = \"мама помыла окно\"\n",
    "\n",
    "# пример работы наивной функции\n",
    "augment_word2vec(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWFKcZshiBDY"
   },
   "source": [
    "Измените функцию так, чтобы заменялись слова, относящиеся к заданному набору пос-тегов (например, ADJ, NOUN), и сохранялась грамматика (1 балл). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AvukGlGgiWnI"
   },
   "outputs": [],
   "source": [
    "def augment_word2vec_pos(sentence, model=model):\n",
    "    res = []\n",
    "    for word in sentence.split():\n",
    "        normal_form = morph.parse(word)[0]\n",
    "        word_POS = normal_form.normal_form + \"_\" + str(normal_form.tag.POS)\n",
    "        if word_POS in model:\n",
    "            for word_closest in model.most_similar(positive=[word_POS]):\n",
    "                word_closest = word_closest[0].split(\"_\")\n",
    "                if word_closest[1] == str(normal_form.tag.POS):\n",
    "                    res.append(word_closest)\n",
    "                    break\n",
    "    res = [i[0] for i in res]\n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'бабушка вымывать окошко'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"мама помыла окно\"\n",
    "\n",
    "# пример работы наивной функции\n",
    "augment_word2vec_pos(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73dUkvww8xzM"
   },
   "source": [
    "### Блок 2: Регрессия; Medium Stories (до 8 баллов)\n",
    "\n",
    "Датасет можно скачать [здесь](https://yadi.sk/d/90JykTO48fL6qw) или со страницы кегли. Можно взять подвыборку.\n",
    "\n",
    "\n",
    "\n",
    "Подзадачи:\n",
    "\n",
    "1.   Эксплоративный анализ данных (1 балл)\n",
    "2.   Отбор важных признаков, поиск гиперпараметров, минимизация переобучения (2 балла)\n",
    "3.   Адаптация аугментации данных с заменой слов (1 балл)\n",
    "4.   Конструирование текстовых признаков (2 балла)\n",
    "5.   Сравнение качества моделей, выбор наилучшей (1 балл)\n",
    "6.   Анализ ошибок (1 балл)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксплоративный анализ данных (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "_rzfLN_pCT7r",
    "outputId": "a6d2578e-8934-453a-b013-c8d76851ede0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1278675</th>\n",
       "      <td>The Address for Innovation is 1717</td>\n",
       "      <td>By Rasheeda N. Creighton, Director, 1717 Innov...</td>\n",
       "      <td>1</td>\n",
       "      <td>Capital One Tech</td>\n",
       "      <td>Capital One Tech</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>https://medium.com/capitalonetech/the-address-...</td>\n",
       "      <td>https://medium.com/@CapitalOneTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285468</th>\n",
       "      <td>Men are all the Same</td>\n",
       "      <td>Why does he stare at me like that? Ive never s...</td>\n",
       "      <td>1</td>\n",
       "      <td>Willis G. Ford</td>\n",
       "      <td>The Creative Cafe</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>https://thecreative.cafe/men-are-all-the-same-...</td>\n",
       "      <td>https://thecreative.cafe/@whun450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463151</th>\n",
       "      <td>Dance of the Moon</td>\n",
       "      <td>Todays Focail do a Chara</td>\n",
       "      <td>1</td>\n",
       "      <td>Christine Salkin Davis</td>\n",
       "      <td>Poets Unlimited</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>https://medium.com/poets-unlimited/dance-of-th...</td>\n",
       "      <td>https://medium.com/@csdavis2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340807</th>\n",
       "      <td>Should You Quit Your Day Job?</td>\n",
       "      <td>Should I quit my day job? Ah, the question so ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Cristofer Jeschke</td>\n",
       "      <td>The Startup</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>584</td>\n",
       "      <td>https://medium.com/swlh/should-you-quit-your-d...</td>\n",
       "      <td>https://medium.com/@crisjeschke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348325</th>\n",
       "      <td>You look happy</td>\n",
       "      <td>It is Tuesday</td>\n",
       "      <td>1</td>\n",
       "      <td>Percy Bharucha</td>\n",
       "      <td>The Haven</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>https://medium.com/the-haven/you-look-happy-ee...</td>\n",
       "      <td>https://medium.com/@percy.bharucha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title  \\\n",
       "1278675  The Address for Innovation is 1717   \n",
       "285468                 Men are all the Same   \n",
       "463151                    Dance of the Moon   \n",
       "1340807       Should You Quit Your Day Job?   \n",
       "1348325                      You look happy   \n",
       "\n",
       "                                                  Subtitle  Image  \\\n",
       "1278675  By Rasheeda N. Creighton, Director, 1717 Innov...      1   \n",
       "285468   Why does he stare at me like that? Ive never s...      1   \n",
       "463151                            Todays Focail do a Chara      1   \n",
       "1340807  Should I quit my day job? Ah, the question so ...      1   \n",
       "1348325                                      It is Tuesday      1   \n",
       "\n",
       "                         Author        Publication  Year  Month  Day  \\\n",
       "1278675        Capital One Tech   Capital One Tech  2018      4   16   \n",
       "285468           Willis G. Ford  The Creative Cafe  2018      2   27   \n",
       "463151   Christine Salkin Davis    Poets Unlimited  2017     11   27   \n",
       "1340807       Cristofer Jeschke        The Startup  2018      2   13   \n",
       "1348325          Percy Bharucha          The Haven  2018      7   10   \n",
       "\n",
       "         Reading_Time  Claps  \\\n",
       "1278675             5     39   \n",
       "285468              2     34   \n",
       "463151              1     34   \n",
       "1340807             5    584   \n",
       "1348325             1     47   \n",
       "\n",
       "                                                       url  \\\n",
       "1278675  https://medium.com/capitalonetech/the-address-...   \n",
       "285468   https://thecreative.cafe/men-are-all-the-same-...   \n",
       "463151   https://medium.com/poets-unlimited/dance-of-th...   \n",
       "1340807  https://medium.com/swlh/should-you-quit-your-d...   \n",
       "1348325  https://medium.com/the-haven/you-look-happy-ee...   \n",
       "\n",
       "                                 Author_url  \n",
       "1278675  https://medium.com/@CapitalOneTech  \n",
       "285468    https://thecreative.cafe/@whun450  \n",
       "463151         https://medium.com/@csdavis2  \n",
       "1340807     https://medium.com/@crisjeschke  \n",
       "1348325  https://medium.com/@percy.bharucha  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# можно не использовать колонки с тегами\n",
    "usecols = [\"Title\", \"Subtitle\", \"Image\", \"Author\", \"Publication\", \"Year\", \"Month\", \"Day\", \"Reading_Time\", \"Claps\", \"url\", \"Author_url\"]\n",
    "\n",
    "df = pd.read_csv(\"Medium_Clean.csv\", sep=\",\", usecols=usecols)\n",
    "df[\"Claps\"] = df[\"Claps\"].astype(int)\n",
    "data = df.dropna()\n",
    "data = data.sample(n=10000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1278675 to 1295001\n",
      "Data columns (total 12 columns):\n",
      "Title           10000 non-null object\n",
      "Subtitle        10000 non-null object\n",
      "Image           10000 non-null int64\n",
      "Author          10000 non-null object\n",
      "Publication     10000 non-null object\n",
      "Year            10000 non-null int64\n",
      "Month           10000 non-null int64\n",
      "Day             10000 non-null int64\n",
      "Reading_Time    10000 non-null int64\n",
      "Claps           10000 non-null int64\n",
      "url             10000 non-null object\n",
      "Author_url      10000 non-null object\n",
      "dtypes: int64(6), object(6)\n",
      "memory usage: 1015.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018    0.5819\n",
       "2017    0.4181\n",
       "Name: Year, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Year.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    0.0904\n",
       "3     0.0887\n",
       "1     0.0885\n",
       "8     0.0885\n",
       "11    0.0844\n",
       "9     0.0842\n",
       "7     0.0813\n",
       "5     0.0810\n",
       "2     0.0809\n",
       "4     0.0799\n",
       "6     0.0789\n",
       "12    0.0733\n",
       "Name: Month, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Month.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество симвоолов в подзаголовках:  86.4394\n",
      "Среднее количество символов в заглавлении:  36.6451\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее количество симвоолов в подзаголовках: \", np.mean([len(i) for i in data.Subtitle.values]))\n",
    "print(\"Среднее количество символов в заглавлении: \", np.mean([len(i) for i in data.Title.values]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор важных признаков, поиск гиперпараметров, минимизация переобучения (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['process_subtitle'] = data.Subtitle.apply(my_preprocess)\n",
    "data['title_len'] = data['Title'].apply(len)\n",
    "data['Subtitle_len'] = data['Subtitle'].apply(len)#(lambda x: len(x.split()))\n",
    "data['tit_sub_len'] = data['Subtitle'].apply(lambda x: len(x.split()))\n",
    "data['process_subtitle_len'] = data['process_subtitle'].apply(len)#(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>title_len</th>\n",
       "      <th>Subtitle_len</th>\n",
       "      <th>tit_sub_len</th>\n",
       "      <th>process_subtitle_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008762</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>0.076910</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>-0.300532</td>\n",
       "      <td>-0.542544</td>\n",
       "      <td>-0.514340</td>\n",
       "      <td>-0.544244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>-0.008762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.855630</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.027662</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.004124</td>\n",
       "      <td>0.001497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>0.013668</td>\n",
       "      <td>-0.855630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023149</td>\n",
       "      <td>-0.014007</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>-0.020687</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.010301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>0.013434</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>-0.023149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025955</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>-0.010429</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>-0.011387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reading_Time</th>\n",
       "      <td>0.076910</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>-0.014007</td>\n",
       "      <td>-0.025955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>0.100369</td>\n",
       "      <td>-0.049653</td>\n",
       "      <td>-0.050678</td>\n",
       "      <td>-0.048444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claps</th>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>0.058519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>-0.027065</td>\n",
       "      <td>-0.027720</td>\n",
       "      <td>-0.027579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_len</th>\n",
       "      <td>-0.300532</td>\n",
       "      <td>0.027662</td>\n",
       "      <td>-0.020687</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>0.100369</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>0.064245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subtitle_len</th>\n",
       "      <td>-0.542544</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>-0.010429</td>\n",
       "      <td>-0.049653</td>\n",
       "      <td>-0.027065</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982772</td>\n",
       "      <td>0.968728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tit_sub_len</th>\n",
       "      <td>-0.514340</td>\n",
       "      <td>-0.004124</td>\n",
       "      <td>-0.005931</td>\n",
       "      <td>-0.011188</td>\n",
       "      <td>-0.050678</td>\n",
       "      <td>-0.027720</td>\n",
       "      <td>0.022285</td>\n",
       "      <td>0.982772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>process_subtitle_len</th>\n",
       "      <td>-0.544244</td>\n",
       "      <td>0.001497</td>\n",
       "      <td>-0.010301</td>\n",
       "      <td>-0.011387</td>\n",
       "      <td>-0.048444</td>\n",
       "      <td>-0.027579</td>\n",
       "      <td>0.064245</td>\n",
       "      <td>0.968728</td>\n",
       "      <td>0.923800</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Image      Year     Month       Day  Reading_Time  \\\n",
       "Image                 1.000000 -0.008762  0.013668  0.013434      0.076910   \n",
       "Year                 -0.008762  1.000000 -0.855630  0.007539      0.034853   \n",
       "Month                 0.013668 -0.855630  1.000000 -0.023149     -0.014007   \n",
       "Day                   0.013434  0.007539 -0.023149  1.000000     -0.025955   \n",
       "Reading_Time          0.076910  0.034853 -0.014007 -0.025955      1.000000   \n",
       "Claps                 0.041097  0.012627 -0.010246 -0.000652      0.058519   \n",
       "title_len            -0.300532  0.027662 -0.020687 -0.012087      0.100369   \n",
       "Subtitle_len         -0.542544 -0.001340 -0.008138 -0.010429     -0.049653   \n",
       "tit_sub_len          -0.514340 -0.004124 -0.005931 -0.011188     -0.050678   \n",
       "process_subtitle_len -0.544244  0.001497 -0.010301 -0.011387     -0.048444   \n",
       "\n",
       "                         Claps  title_len  Subtitle_len  tit_sub_len  \\\n",
       "Image                 0.041097  -0.300532     -0.542544    -0.514340   \n",
       "Year                  0.012627   0.027662     -0.001340    -0.004124   \n",
       "Month                -0.010246  -0.020687     -0.008138    -0.005931   \n",
       "Day                  -0.000652  -0.012087     -0.010429    -0.011188   \n",
       "Reading_Time          0.058519   0.100369     -0.049653    -0.050678   \n",
       "Claps                 1.000000   0.005435     -0.027065    -0.027720   \n",
       "title_len             0.005435   1.000000      0.040418     0.022285   \n",
       "Subtitle_len         -0.027065   0.040418      1.000000     0.982772   \n",
       "tit_sub_len          -0.027720   0.022285      0.982772     1.000000   \n",
       "process_subtitle_len -0.027579   0.064245      0.968728     0.923800   \n",
       "\n",
       "                      process_subtitle_len  \n",
       "Image                            -0.544244  \n",
       "Year                              0.001497  \n",
       "Month                            -0.010301  \n",
       "Day                              -0.011387  \n",
       "Reading_Time                     -0.048444  \n",
       "Claps                            -0.027579  \n",
       "title_len                         0.064245  \n",
       "Subtitle_len                      0.968728  \n",
       "tit_sub_len                       0.923800  \n",
       "process_subtitle_len              1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "data[['title_len',\n",
    "      'Subtitle_len',\n",
    "      'tit_sub_len',\n",
    "      'process_subtitle_len']] = scaler.fit_transform(data[['title_len',\n",
    "                                                            'Subtitle_len',\n",
    "                                                            'tit_sub_len',\n",
    "                                                            'process_subtitle_len']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['title_len', 'Subtitle_len', \"process_subtitle_len\", 'tit_sub_len', 'Image', 'Year', 'Reading_Time']].values\n",
    "y = data.Claps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Image', 'Year', 'Reading_Time']].values\n",
    "y = data.Claps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  1 Model:  LinearRegression RMSE:  1447.98717311356 R2 score:  0.0030541955519113317\n",
      "Alpha:  1 Model:  Ridge RMSE:  1447.986941638942 R2 score:  0.0030545142945563875\n",
      "Alpha:  1 Model:  Lasso RMSE:  1448.0016573679723 R2 score:  0.0030342505010750864\n",
      "Alpha:  1 Model:  ElasticNet RMSE:  1448.6446032221181 R2 score:  0.002148702752807541\n",
      "Alpha:  0.1 Model:  LinearRegression RMSE:  1447.98717311356 R2 score:  0.0030541955519113317\n",
      "Alpha:  0.1 Model:  Ridge RMSE:  1447.9871498834289 R2 score:  0.003054227540014276\n",
      "Alpha:  0.1 Model:  Lasso RMSE:  1447.9883606234653 R2 score:  0.00305256033921697\n",
      "Alpha:  0.1 Model:  ElasticNet RMSE:  1447.9893790458766 R2 score:  0.0030511579605789763\n",
      "Alpha:  0.01 Model:  LinearRegression RMSE:  1447.98717311356 R2 score:  0.0030541955519113317\n",
      "Alpha:  0.01 Model:  Ridge RMSE:  1447.9871707897196 R2 score:  0.0030541987518606373\n",
      "Alpha:  0.01 Model:  Lasso RMSE:  1447.9872892524218 R2 score:  0.003054035627627627\n",
      "Alpha:  0.01 Model:  ElasticNet RMSE:  1447.9797679724782 R2 score:  0.0030643924729785166\n",
      "Alpha:  0.001 Model:  LinearRegression RMSE:  1447.98717311356 R2 score:  0.0030541955519113317\n",
      "Alpha:  0.001 Model:  Ridge RMSE:  1447.987172881168 R2 score:  0.0030541958719171314\n",
      "Alpha:  0.001 Model:  Lasso RMSE:  1447.9871846983756 R2 score:  0.0030541795995137067\n",
      "Alpha:  0.001 Model:  ElasticNet RMSE:  1447.9863204323585 R2 score:  0.003055369701395194\n",
      "Alpha:  0.0001 Model:  LinearRegression RMSE:  1447.98717311356 R2 score:  0.0030541955519113317\n",
      "Alpha:  0.0001 Model:  Ridge RMSE:  1447.9871730903214 R2 score:  0.003054195583910735\n",
      "Alpha:  0.0001 Model:  Lasso RMSE:  1447.9871742688013 R2 score:  0.003054193961133378\n",
      "Alpha:  0.0001 Model:  ElasticNet RMSE:  1447.9870866724632 R2 score:  0.0030543145820902673\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for alpha in [1, 0.1, 0.01, 0.001, 0.0001]:\n",
    "    for model in [LinearRegression(alpha), Ridge(alpha), Lasso(alpha), ElasticNet(alpha)]:\n",
    "#         reg = Ridge(alpha=0.01)\n",
    "        reg = model\n",
    "        reg.fit(X_train, y_train)\n",
    "        x_pred = reg.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, x_pred))\n",
    "        r2 = r2_score(y_test, x_pred)\n",
    "        models.append((alpha, str(model).split('(')[0], rmse, r2))\n",
    "        print(\"Alpha: \", alpha,\n",
    "              \"Model: \", str(model).split('(')[0],\n",
    "              \"RMSE: \", rmse,\n",
    "              \"R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  (0.01, 'ElasticNet', 1447.9797679724782, 0.0030643924729785166)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: \", sorted(models, key=lambda x: x[2])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Конструирование текстовых признаков (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['title_len',\n",
    "                                                          'Subtitle_len',\n",
    "                                                          \"process_subtitle_len\",\n",
    "                                                          'Image',\n",
    "                                                          'Year',\n",
    "                                                          'Reading_Time',\n",
    "                                                          'process_subtitle']],\n",
    "                                                    data.Claps.values,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "\n",
    "subtitle_vectors_train = vectorizer.fit_transform(X_train.process_subtitle.values)\n",
    "X_train = X_train.drop(['process_subtitle'], axis=1)\n",
    "print(X_train.values.shape)\n",
    "X_train = np.concatenate((X_train.values, subtitle_vectors_train.toarray()), axis=1)\n",
    "\n",
    "subtitle_vectors_test = vectorizer.transform(X_test.process_subtitle.values)\n",
    "X_test = X_test.drop(['process_subtitle'], axis=1)\n",
    "X_test = np.concatenate((X_test.values, subtitle_vectors_test.toarray()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  1 Model:  LinearRegression RMSE:  1467.2551437222348 R2 score:  -0.023654504767798956\n",
      "Alpha:  1 Model:  Ridge RMSE:  1462.9834329773785 R2 score:  -0.01770272381387894\n",
      "Alpha:  1 Model:  Lasso RMSE:  1458.387368727978 R2 score:  -0.01131840015194907\n",
      "Alpha:  1 Model:  ElasticNet RMSE:  1448.426774979116 R2 score:  0.0024487678653692946\n",
      "Alpha:  0.1 Model:  LinearRegression RMSE:  1467.2551437222348 R2 score:  -0.023654504767798956\n",
      "Alpha:  0.1 Model:  Ridge RMSE:  1466.7489741398144 R2 score:  -0.0229483516468314\n",
      "Alpha:  0.1 Model:  Lasso RMSE:  1462.762050762578 R2 score:  -0.017394744610069734\n",
      "Alpha:  0.1 Model:  ElasticNet RMSE:  1447.677011076612 R2 score:  0.0034812457771293825\n",
      "Alpha:  0.01 Model:  LinearRegression RMSE:  1467.2551437222348 R2 score:  -0.023654504767798956\n",
      "Alpha:  0.01 Model:  Ridge RMSE:  1467.2035762778046 R2 score:  -0.023582552293277326\n",
      "Alpha:  0.01 Model:  Lasso RMSE:  1466.7052543346063 R2 score:  -0.022887369928864087\n",
      "Alpha:  0.01 Model:  ElasticNet RMSE:  1447.139593879671 R2 score:  0.0042209783373564624\n",
      "Alpha:  0.001 Model:  LinearRegression RMSE:  1467.2551437222348 R2 score:  -0.023654504767798956\n",
      "Alpha:  0.001 Model:  Ridge RMSE:  1467.2499772878482 R2 score:  -0.02364729588590131\n",
      "Alpha:  0.001 Model:  Lasso RMSE:  1467.1993013793312 R2 score:  -0.02357658760618664\n",
      "Alpha:  0.001 Model:  ElasticNet RMSE:  1456.4271390264364 R2 score:  -0.0086015855146091\n",
      "Alpha:  0.0001 Model:  LinearRegression RMSE:  1467.2551437222348 R2 score:  -0.023654504767798956\n",
      "Alpha:  0.0001 Model:  Ridge RMSE:  1467.254626981714 R2 score:  -0.023653783743004864\n",
      "Alpha:  0.0001 Model:  Lasso RMSE:  1467.249541010439 R2 score:  -0.02364668713602147\n",
      "Alpha:  0.0001 Model:  ElasticNet RMSE:  1465.4559043499858 R2 score:  -0.021145506613005738\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for alpha in [1, 0.1, 0.01, 0.001, 0.0001]:\n",
    "    for model in [LinearRegression(alpha), Ridge(alpha), Lasso(alpha), ElasticNet(alpha)]:\n",
    "#         reg = Ridge(alpha=0.01)\n",
    "        reg = model\n",
    "        reg.fit(X_train, y_train)\n",
    "        x_pred = reg.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, x_pred))\n",
    "        r2 = r2_score(y_test, x_pred)\n",
    "        models.append((alpha, str(model).split('(')[0], rmse, r2))\n",
    "        print(\"Alpha: \", alpha,\n",
    "              \"Model: \", str(model).split('(')[0],\n",
    "              \"RMSE: \", rmse,\n",
    "              \"R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  (0.01, 'ElasticNet', 1447.139593879671, 0.0042209783373564624)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: \", sorted(models, key=lambda x: x[2])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Адаптация аугментации данных с заменой слов (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data[[i for i in data.columns if i != 'Title' and i != 'Subtitle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "      <th>process_subtitle</th>\n",
       "      <th>title_len</th>\n",
       "      <th>Subtitle_len</th>\n",
       "      <th>tit_sub_len</th>\n",
       "      <th>process_subtitle_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1278675</th>\n",
       "      <td>1</td>\n",
       "      <td>Capital One Tech</td>\n",
       "      <td>Capital One Tech</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>https://medium.com/capitalonetech/the-address-...</td>\n",
       "      <td>https://medium.com/@CapitalOneTech</td>\n",
       "      <td>rasheeda n creighton director 1717 innovation ...</td>\n",
       "      <td>-0.135616</td>\n",
       "      <td>-0.226782</td>\n",
       "      <td>-0.416568</td>\n",
       "      <td>0.054884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285468</th>\n",
       "      <td>1</td>\n",
       "      <td>Willis G. Ford</td>\n",
       "      <td>The Creative Cafe</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>https://thecreative.cafe/men-are-all-the-same-...</td>\n",
       "      <td>https://thecreative.cafe/@whun450</td>\n",
       "      <td>stare like ive never seen dude looks like problem</td>\n",
       "      <td>-0.853407</td>\n",
       "      <td>0.434202</td>\n",
       "      <td>0.837652</td>\n",
       "      <td>-0.255135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463151</th>\n",
       "      <td>1</td>\n",
       "      <td>Christine Salkin Davis</td>\n",
       "      <td>Poets Unlimited</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>https://medium.com/poets-unlimited/dance-of-th...</td>\n",
       "      <td>https://medium.com/@csdavis2</td>\n",
       "      <td>todays focail chara</td>\n",
       "      <td>-1.007219</td>\n",
       "      <td>-0.917143</td>\n",
       "      <td>-0.834641</td>\n",
       "      <td>-0.875172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340807</th>\n",
       "      <td>1</td>\n",
       "      <td>Cristofer Jeschke</td>\n",
       "      <td>The Startup</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>584</td>\n",
       "      <td>https://medium.com/swlh/should-you-quit-your-d...</td>\n",
       "      <td>https://medium.com/@crisjeschke</td>\n",
       "      <td>quit day job ah question many us ask</td>\n",
       "      <td>-0.391970</td>\n",
       "      <td>-0.373667</td>\n",
       "      <td>-0.082110</td>\n",
       "      <td>-0.523818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348325</th>\n",
       "      <td>1</td>\n",
       "      <td>Percy Bharucha</td>\n",
       "      <td>The Haven</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>https://medium.com/the-haven/you-look-happy-ee...</td>\n",
       "      <td>https://medium.com/@percy.bharucha</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>-1.161032</td>\n",
       "      <td>-1.078716</td>\n",
       "      <td>-1.001871</td>\n",
       "      <td>-1.123187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image                  Author        Publication  Year  Month  Day  \\\n",
       "1278675      1        Capital One Tech   Capital One Tech  2018      4   16   \n",
       "285468       1          Willis G. Ford  The Creative Cafe  2018      2   27   \n",
       "463151       1  Christine Salkin Davis    Poets Unlimited  2017     11   27   \n",
       "1340807      1       Cristofer Jeschke        The Startup  2018      2   13   \n",
       "1348325      1          Percy Bharucha          The Haven  2018      7   10   \n",
       "\n",
       "         Reading_Time  Claps  \\\n",
       "1278675             5     39   \n",
       "285468              2     34   \n",
       "463151              1     34   \n",
       "1340807             5    584   \n",
       "1348325             1     47   \n",
       "\n",
       "                                                       url  \\\n",
       "1278675  https://medium.com/capitalonetech/the-address-...   \n",
       "285468   https://thecreative.cafe/men-are-all-the-same-...   \n",
       "463151   https://medium.com/poets-unlimited/dance-of-th...   \n",
       "1340807  https://medium.com/swlh/should-you-quit-your-d...   \n",
       "1348325  https://medium.com/the-haven/you-look-happy-ee...   \n",
       "\n",
       "                                 Author_url  \\\n",
       "1278675  https://medium.com/@CapitalOneTech   \n",
       "285468    https://thecreative.cafe/@whun450   \n",
       "463151         https://medium.com/@csdavis2   \n",
       "1340807     https://medium.com/@crisjeschke   \n",
       "1348325  https://medium.com/@percy.bharucha   \n",
       "\n",
       "                                          process_subtitle  title_len  \\\n",
       "1278675  rasheeda n creighton director 1717 innovation ...  -0.135616   \n",
       "285468   stare like ive never seen dude looks like problem  -0.853407   \n",
       "463151                                 todays focail chara  -1.007219   \n",
       "1340807               quit day job ah question many us ask  -0.391970   \n",
       "1348325                                            tuesday  -1.161032   \n",
       "\n",
       "         Subtitle_len  tit_sub_len  process_subtitle_len  \n",
       "1278675     -0.226782    -0.416568              0.054884  \n",
       "285468       0.434202     0.837652             -0.255135  \n",
       "463151      -0.917143    -0.834641             -0.875172  \n",
       "1340807     -0.373667    -0.082110             -0.523818  \n",
       "1348325     -1.078716    -1.001871             -1.123187  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4518.42it/s]\n",
      "100%|██████████| 10000/10000 [00:07<00:00, 1324.30it/s]\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "title_buf = []\n",
    "subtitle_buf = []\n",
    "\n",
    "for i in tqdm(data.Title.values):\n",
    "    title_buf.append(augment_word2vec(i))\n",
    "\n",
    "for i in tqdm(data.Subtitle.values):\n",
    "    subtitle_buf.append(augment_word2vec(i))\n",
    "\n",
    "data2[\"Title\"] = title_buf #data.Title.apply(augment_word2vec)\n",
    "data2[\"Subtitle\"] = subtitle_buf #data.Subtitle.apply(augment_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augm = pd.concat([data, data2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 17 columns):\n",
      "Author                  20000 non-null object\n",
      "Author_url              20000 non-null object\n",
      "Claps                   20000 non-null int64\n",
      "Day                     20000 non-null int64\n",
      "Image                   20000 non-null int64\n",
      "Month                   20000 non-null int64\n",
      "Publication             20000 non-null object\n",
      "Reading_Time            20000 non-null int64\n",
      "Subtitle                20000 non-null object\n",
      "Subtitle_len            20000 non-null float64\n",
      "Title                   20000 non-null object\n",
      "Year                    20000 non-null int64\n",
      "process_subtitle        20000 non-null object\n",
      "process_subtitle_len    20000 non-null float64\n",
      "tit_sub_len             20000 non-null float64\n",
      "title_len               20000 non-null float64\n",
      "url                     20000 non-null object\n",
      "dtypes: float64(4), int64(6), object(7)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_augm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augm['title_len'] = data_augm['Title'].apply(len)\n",
    "data_augm['Subtitle_len'] = data_augm['Subtitle'].apply(len)#(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augm['process_subtitle'] = data_augm.Subtitle.apply(my_preprocess)\n",
    "data_augm['title_len'] = data_augm['Title'].apply(len)\n",
    "data_augm['Subtitle_len'] = data_augm['Subtitle'].apply(len)#(lambda x: len(x.split()))\n",
    "data_augm['tit_sub_len'] = data_augm['Subtitle'].apply(lambda x: len(x.split()))\n",
    "data_augm['process_subtitle_len'] = data_augm['process_subtitle'].apply(len)#(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_augm[['title_len',\n",
    "                                                          'Subtitle_len',\n",
    "                                                          \"process_subtitle_len\",\n",
    "                                                          'Image',\n",
    "                                                          'Year',\n",
    "                                                          'Reading_Time',\n",
    "                                                          'process_subtitle']],\n",
    "                                                    data_augm.Claps.values,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "\n",
    "subtitle_vectors_train = vectorizer.fit_transform(X_train.process_subtitle.values)\n",
    "X_train = X_train.drop(['process_subtitle'], axis=1)\n",
    "print(X_train.values.shape)\n",
    "X_train = np.concatenate((X_train.values, subtitle_vectors_train.toarray()), axis=1)\n",
    "\n",
    "subtitle_vectors_test = vectorizer.transform(X_test.process_subtitle.values)\n",
    "X_test = X_test.drop(['process_subtitle'], axis=1)\n",
    "X_test = np.concatenate((X_test.values, subtitle_vectors_test.toarray()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:  1 Model:  LinearRegression RMSE:  2523.7548717308823 R2 score:  -0.004040489573794215\n",
      "Alpha:  1 Model:  Ridge RMSE:  2521.3909516366675 R2 score:  -0.002160465536560574\n",
      "Alpha:  1 Model:  Lasso RMSE:  2515.8461618583674 R2 score:  0.0022423892905519827\n",
      "Alpha:  1 Model:  ElasticNet RMSE:  2513.36869026838 R2 score:  0.004206499072673675\n",
      "Alpha:  0.1 Model:  LinearRegression RMSE:  2523.7548717308823 R2 score:  -0.004040489573794215\n",
      "Alpha:  0.1 Model:  Ridge RMSE:  2523.4723679638946 R2 score:  -0.0038157218292182993\n",
      "Alpha:  0.1 Model:  Lasso RMSE:  2521.296307439298 R2 score:  -0.0020852317512636276\n",
      "Alpha:  0.1 Model:  ElasticNet RMSE:  2512.595965123801 R2 score:  0.004818710400043891\n",
      "Alpha:  0.01 Model:  LinearRegression RMSE:  2523.7548717308823 R2 score:  -0.004040489573794215\n",
      "Alpha:  0.01 Model:  Ridge RMSE:  2523.7260575060272 R2 score:  -0.004017563033977822\n",
      "Alpha:  0.01 Model:  Lasso RMSE:  2523.385215574879 R2 score:  -0.0037463860768800483\n",
      "Alpha:  0.01 Model:  ElasticNet RMSE:  2512.492309624437 R2 score:  0.00490081980971091\n",
      "Alpha:  0.001 Model:  LinearRegression RMSE:  2523.7548717308823 R2 score:  -0.004040489573794215\n",
      "Alpha:  0.001 Model:  Ridge RMSE:  2523.751984533344 R2 score:  -0.0040381923129910735\n",
      "Alpha:  0.001 Model:  Lasso RMSE:  2523.7158315530287 R2 score:  -0.0040094266393180256\n",
      "Alpha:  0.001 Model:  ElasticNet RMSE:  2515.687452209404 R2 score:  0.0023682704097970353\n",
      "Alpha:  0.0001 Model:  LinearRegression RMSE:  2523.7548717308823 R2 score:  -0.004040489573794215\n",
      "Alpha:  0.0001 Model:  Ridge RMSE:  2523.754582953233 R2 score:  -0.004040259801529444\n",
      "Alpha:  0.0001 Model:  Lasso RMSE:  2523.750947049281 R2 score:  -0.004037366817129628\n",
      "Alpha:  0.0001 Model:  ElasticNet RMSE:  2521.8962926193426 R2 score:  -0.0025622148203297\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for alpha in [1, 0.1, 0.01, 0.001, 0.0001]:\n",
    "    for model in [LinearRegression(alpha), Ridge(alpha), Lasso(alpha), ElasticNet(alpha)]:\n",
    "#         reg = Ridge(alpha=0.01)\n",
    "        reg = model\n",
    "        reg.fit(X_train, y_train)\n",
    "        x_pred = reg.predict(X_test)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, x_pred))\n",
    "        r2 = r2_score(y_test, x_pred)\n",
    "        models.append((alpha, str(model).split('(')[0], rmse, r2))\n",
    "        print(\"Alpha: \", alpha,\n",
    "              \"Model: \", str(model).split('(')[0],\n",
    "              \"RMSE: \", rmse,\n",
    "              \"R2 score: \", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение качества моделей, выбор наилучшей (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель с дополнительными аугментированными данными показала результат лучше исходных данных, поэтому возьмём наилучшую модель на аугментированных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:  (0.01, 'ElasticNet', 2512.492309624437, 0.00490081980971091)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model: \", sorted(models, key=lambda x: x[2])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ ошибок (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слишком низкий показатель r2 и слишком большая ошибка, пыталась сделать всё по чёткому плану, ноrmse остаётся слишком большим при любых изменениях. Можно выделить другие признаки, не только вектора tf-idf и обучить на них нелинейные модели, для получения более глубоких зависимостей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9SrNOmbEf_p"
   },
   "source": [
    "### Блок 3: Paraphrase Detection (до 8 баллов)\n",
    "\n",
    "\n",
    "* [Статья по русскоязычному корпусу парафразов](https://www.aclweb.org/anthology/2020.ngt-1.6/)\n",
    "* [Еще статья](http://www.dialog-21.ru/media/3928/loukachevitchnvetal.pdf)\n",
    "* [Сайт корпуса](http://paraphraser.ru/)\n",
    "\n",
    "Отформатированные данные можно скачать [здесь](https://yadi.sk/d/OIgbnRA6OVJ4VQ)\n",
    "\n",
    "\n",
    "1.   Эксплоративный анализ данных (1 балл)\n",
    "2.   Поиск гиперпараметров, минимизация переобучения (2 балла)\n",
    "3.   Аугментация данных (1 балл)\n",
    "4.   Сравнение качества моделей, выбор наилучшей (1 балл)\n",
    "5.   Конструирование текстовых признаков (2 балла)\n",
    "6.   Анализ ошибок (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "iDXYQu_uWSGm",
    "outputId": "5c0937bf-6fcf-47a6-cb26-a87d4a44dbe1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Совет юстиции Бразилии легализовал однополые б...</td>\n",
       "      <td>Совет юстиции Бразилии разрешил однополые браки.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Магнит\" поручится перед \"Абсолют Банком\" за к...</td>\n",
       "      <td>Выпуск сигарет в России упал из-за антитабачно...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ЕС призвал США не бомбить Сирию до публикации ...</td>\n",
       "      <td>Евросоюз призвал США дождаться доклада ООН по ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Депо Московского метрополитена впервые перейде...</td>\n",
       "      <td>Частной компании впервые отдадут депо в москов...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Два человека погибли в столкновениях между кур...</td>\n",
       "      <td>Один человек погиб при столкновении судов у бе...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  Совет юстиции Бразилии легализовал однополые б...   \n",
       "1  \"Магнит\" поручится перед \"Абсолют Банком\" за к...   \n",
       "2  ЕС призвал США не бомбить Сирию до публикации ...   \n",
       "3  Депо Московского метрополитена впервые перейде...   \n",
       "4  Два человека погибли в столкновениях между кур...   \n",
       "\n",
       "                                              text_2  class  \n",
       "0   Совет юстиции Бразилии разрешил однополые браки.      1  \n",
       "1  Выпуск сигарет в России упал из-за антитабачно...     -1  \n",
       "2  Евросоюз призвал США дождаться доклада ООН по ...     -1  \n",
       "3  Частной компании впервые отдадут депо в москов...      1  \n",
       "4  Один человек погиб при столкновении судов у бе...     -1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = pd.read_csv(\"paraphrases.tsv\", sep=\"\\t\")\n",
    "para.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксплоративный анализ данных (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### В датасете много повторений, оставим только уникальные текстовые пары"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3789"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(para.text_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4256"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_duplicate = []\n",
    "normal = []\n",
    "for value in para.values:\n",
    "    if (value[0] + value[1] not in non_duplicate):\n",
    "        normal.append(value)\n",
    "    non_duplicate.append(value[0] + value[1])\n",
    "    non_duplicate.append(value[1] + value[0])\n",
    "len(normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Совет юстиции Бразилии легализовал однополые б...</td>\n",
       "      <td>Совет юстиции Бразилии разрешил однополые браки.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Магнит\" поручится перед \"Абсолют Банком\" за к...</td>\n",
       "      <td>Выпуск сигарет в России упал из-за антитабачно...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ЕС призвал США не бомбить Сирию до публикации ...</td>\n",
       "      <td>Евросоюз призвал США дождаться доклада ООН по ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Депо Московского метрополитена впервые перейде...</td>\n",
       "      <td>Частной компании впервые отдадут депо в москов...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Два человека погибли в столкновениях между кур...</td>\n",
       "      <td>Один человек погиб при столкновении судов у бе...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  Совет юстиции Бразилии легализовал однополые б...   \n",
       "1  \"Магнит\" поручится перед \"Абсолют Банком\" за к...   \n",
       "2  ЕС призвал США не бомбить Сирию до публикации ...   \n",
       "3  Депо Московского метрополитена впервые перейде...   \n",
       "4  Два человека погибли в столкновениях между кур...   \n",
       "\n",
       "                                              text_2  class  \n",
       "0   Совет юстиции Бразилии разрешил однополые браки.      1  \n",
       "1  Выпуск сигарет в России упал из-за антитабачно...     -1  \n",
       "2  Евросоюз призвал США дождаться доклада ООН по ...     -1  \n",
       "3  Частной компании впервые отдадут депо в москов...      1  \n",
       "4  Один человек погиб при столкновении судов у бе...     -1  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(normal, columns=['text_1', 'text_2', 'class'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4256 entries, 0 to 4255\n",
      "Data columns (total 3 columns):\n",
      "text_1    4256 non-null object\n",
      "text_2    4256 non-null object\n",
      "class     4256 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 99.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество символов в text_1:  58.5288056206089\n",
      "Среднее количество символов в text_2:  55.04074941451991\n"
     ]
    }
   ],
   "source": [
    "print(\"Среднее количество символов в text_1: \", np.mean([len(i) for i in para.text_1.values]))\n",
    "print(\"Среднее количество символов в text_2: \", np.mean([len(i) for i in para.text_2.values]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Конструирование текстовых признаков (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_1</th>\n",
       "      <th>text_2</th>\n",
       "      <th>class</th>\n",
       "      <th>text_1_normal</th>\n",
       "      <th>text_2_normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Совет юстиции Бразилии легализовал однополые б...</td>\n",
       "      <td>Совет юстиции Бразилии разрешил однополые браки.</td>\n",
       "      <td>1</td>\n",
       "      <td>совет юстиция бразилия легализовать однополый ...</td>\n",
       "      <td>совет юстиция бразилия разрешить однополый брак</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Магнит\" поручится перед \"Абсолют Банком\" за к...</td>\n",
       "      <td>Выпуск сигарет в России упал из-за антитабачно...</td>\n",
       "      <td>-1</td>\n",
       "      <td>магнит поручиться перед абсолют банк за кредит...</td>\n",
       "      <td>выпуск сигарета в россия упасть изз антитабачн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ЕС призвал США не бомбить Сирию до публикации ...</td>\n",
       "      <td>Евросоюз призвал США дождаться доклада ООН по ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>ес призвать сша не бомбить сирия до публикация...</td>\n",
       "      <td>евросоюз призвать сша дождаться доклад оон по ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Депо Московского метрополитена впервые перейде...</td>\n",
       "      <td>Частной компании впервые отдадут депо в москов...</td>\n",
       "      <td>1</td>\n",
       "      <td>депо московский метрополитен впервые перейти в...</td>\n",
       "      <td>частный компания впервые отдать депо в московс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Два человека погибли в столкновениях между кур...</td>\n",
       "      <td>Один человек погиб при столкновении судов у бе...</td>\n",
       "      <td>-1</td>\n",
       "      <td>два человек погибнуть в столкновение между кур...</td>\n",
       "      <td>один человек погибнуть при столкновение судно ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text_1  \\\n",
       "0  Совет юстиции Бразилии легализовал однополые б...   \n",
       "1  \"Магнит\" поручится перед \"Абсолют Банком\" за к...   \n",
       "2  ЕС призвал США не бомбить Сирию до публикации ...   \n",
       "3  Депо Московского метрополитена впервые перейде...   \n",
       "4  Два человека погибли в столкновениях между кур...   \n",
       "\n",
       "                                              text_2  class  \\\n",
       "0   Совет юстиции Бразилии разрешил однополые браки.      1   \n",
       "1  Выпуск сигарет в России упал из-за антитабачно...     -1   \n",
       "2  Евросоюз призвал США дождаться доклада ООН по ...     -1   \n",
       "3  Частной компании впервые отдадут депо в москов...      1   \n",
       "4  Один человек погиб при столкновении судов у бе...     -1   \n",
       "\n",
       "                                       text_1_normal  \\\n",
       "0  совет юстиция бразилия легализовать однополый ...   \n",
       "1  магнит поручиться перед абсолют банк за кредит...   \n",
       "2  ес призвать сша не бомбить сирия до публикация...   \n",
       "3  депо московский метрополитен впервые перейти в...   \n",
       "4  два человек погибнуть в столкновение между кур...   \n",
       "\n",
       "                                       text_2_normal  \n",
       "0    совет юстиция бразилия разрешить однополый брак  \n",
       "1  выпуск сигарета в россия упасть изз антитабачн...  \n",
       "2  евросоюз призвать сша дождаться доклад оон по ...  \n",
       "3  частный компания впервые отдать депо в московс...  \n",
       "4  один человек погибнуть при столкновение судно ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_1_normal'] = data.text_1.apply(my_preprocess)\n",
    "data['text_2_normal'] = data.text_2.apply(my_preprocess)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['text_1_normal','text_2_normal']],\n",
    "                                                    data['class'].values,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(set(X_train.text_1_normal.values + X_train.text_2_normal.values))\n",
    "\n",
    "\n",
    "vec_1 = vectorizer.transform(X_train.text_1_normal.values)\n",
    "vec_2 = vectorizer.transform(X_train.text_2_normal.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# cos_sim = np.linalg.norm(sub, axis=1)\n",
    "# vec_1 = normalize(vec_1, axis=1, norm='l2')\n",
    "# vec_2 = normalize(vec_2, axis=1, norm='l2')\n",
    "\n",
    "cos_sim = []\n",
    "for i in range(vec_1.shape[0]):\n",
    "    if np.linalg.norm(vec_1[i, :].toarray()) == 0 or np.linalg.norm(vec_2[i, :].toarray()) == 0:\n",
    "        cos_sim.append(1.0)\n",
    "        continue\n",
    "\n",
    "    cos_sim.append( distance.cosine(vec_1[i, :].toarray(), vec_2[i, :].toarray()))\n",
    "    \n",
    "# cos_sim = vec_1.dot(vec_2.T).sum(axis=1)\n",
    "X_train['cos_sim'] = np.asarray(cos_sim).reshape(-1)\n",
    "X_train = X_train[['cos_sim']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_1 = vectorizer.transform(X_test.text_1_normal.values)\n",
    "vec_2 = vectorizer.transform(X_test.text_2_normal.values)\n",
    "\n",
    "# sub = vec_1 - vec_2\n",
    "\n",
    "# vec_1 = normalize(vec_1, axis=1, norm='l2')\n",
    "# vec_2 = normalize(vec_2, axis=1, norm='l2')\n",
    "\n",
    "# cos_sim = vec_1.dot(vec_2.T).sum(axis=1)\n",
    "# cos_sim = normalize(vec_1 - vec_2, axis=1, norm='l2').sum(axis=1)\n",
    "cos_sim = []\n",
    "for i in range(vec_1.shape[0]):\n",
    "    if np.linalg.norm(vec_1[i, :].toarray()) == 0 or np.linalg.norm(vec_2[i, :].toarray()) == 0:\n",
    "        cos_sim.append(1.0)\n",
    "        continue\n",
    "\n",
    "    cos_sim.append( distance.cosine(vec_1[i, :].toarray(), vec_2[i, :].toarray()))\n",
    "\n",
    "X_test['cos_sim'] = np.asarray(cos_sim).reshape(-1)\n",
    "X_test = X_test[['cos_sim']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поиск гиперпараметров, минимизация переобучения (2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LogisticRegression accuracy:  0.8045112781954887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "reg = model\n",
    "reg.fit(X_train, y_train)\n",
    "x_pred = reg.predict(X_test)\n",
    "acc = accuracy_score(y_test, x_pred.round())\n",
    "r2 = r2_score(y_test, x_pred)\n",
    "models.append((alpha, str(model).split('(')[0], rmse, r2))\n",
    "print(\"Model: \", str(model).split('(')[0],\n",
    "      \"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация данных (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_1_normal'] = data.text_1_normal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4256/4256 [03:33<00:00, 22.97it/s]\n",
      "100%|██████████| 4256/4256 [03:12<00:00, 22.05it/s]\n"
     ]
    }
   ],
   "source": [
    "buf = []\n",
    "\n",
    "for i in tqdm(data.text_1_normal.values):\n",
    "    buf.append(augment_word2vec(i))\n",
    "\n",
    "data2['text_1_normal'] = buf\n",
    "buf = []\n",
    "\n",
    "for i in tqdm(data.text_2_normal.values):\n",
    "    buf.append(augment_word2vec(i))\n",
    "    \n",
    "data2['text_2_normal'] = buf\n",
    "data2['class'] = data['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data[['text_1_normal', 'text_2_normal', 'class']],\n",
    "                  data2[['text_1_normal', 'text_2_normal', 'class']] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение качества моделей, выбор наилучшей (1 балл)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[['text_1_normal','text_2_normal']],\n",
    "                                                    data['class'].values,\n",
    "                                                    random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(set(X_train.text_1_normal.values + X_train.text_2_normal.values))\n",
    "\n",
    "\n",
    "vec_1 = vectorizer.transform(X_train.text_1_normal.values)\n",
    "vec_2 = vectorizer.transform(X_train.text_2_normal.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  cos_sim = np.linalg.norm(sub, axis=1)\n",
    "# vec_1 = normalize(vec_1, axis=1, norm='l2')\n",
    "# vec_2 = normalize(vec_2, axis=1, norm='l2')\n",
    "\n",
    "cos_sim = []\n",
    "for i in range(vec_1.shape[0]):\n",
    "    if np.linalg.norm(vec_1[i, :].toarray()) == 0 or np.linalg.norm(vec_2[i, :].toarray()) == 0:\n",
    "        cos_sim.append(1.0)\n",
    "        continue\n",
    "\n",
    "    cos_sim.append( distance.cosine(vec_1[i, :].toarray(), vec_2[i, :].toarray()))\n",
    "    \n",
    "# cos_sim = vec_1.dot(vec_2.T).sum(axis=1)\n",
    "X_train['cos_sim'] = np.asarray(cos_sim).reshape(-1)\n",
    "X_train = X_train[['cos_sim']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_1 = vectorizer.transform(X_test.text_1_normal.values)\n",
    "vec_2 = vectorizer.transform(X_test.text_2_normal.values)\n",
    "\n",
    "# sub = vec_1 - vec_2\n",
    "\n",
    "# vec_1 = normalize(vec_1, axis=1, norm='l2')\n",
    "# vec_2 = normalize(vec_2, axis=1, norm='l2')\n",
    "\n",
    "# cos_sim = vec_1.dot(vec_2.T).sum(axis=1)\n",
    "# cos_sim = normalize(vec_1 - vec_2, axis=1, norm='l2').sum(axis=1)\n",
    "cos_sim = []\n",
    "for i in range(vec_1.shape[0]):\n",
    "    if np.linalg.norm(vec_1[i, :].toarray()) == 0 or np.linalg.norm(vec_2[i, :].toarray()) == 0:\n",
    "        cos_sim.append(1.0)\n",
    "        continue\n",
    "\n",
    "    cos_sim.append( distance.cosine(vec_1[i, :].toarray(), vec_2[i, :].toarray()))\n",
    "\n",
    "X_test['cos_sim'] = np.asarray(cos_sim).reshape(-1)\n",
    "X_test = X_test[['cos_sim']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LogisticRegression accuracy:  0.7720864661654135\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "reg = model\n",
    "reg.fit(X_train, y_train)\n",
    "x_pred = reg.predict(X_test)\n",
    "acc = accuracy_score(y_test, x_pred.round())\n",
    "r2 = r2_score(y_test, x_pred)\n",
    "models.append((alpha, str(model).split('(')[0], rmse, r2))\n",
    "print(\"Model: \", str(model).split('(')[0],\n",
    "      \"accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С аугментированными данными accuracy модели ниже, чем без них"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ ошибок (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наверно для улучшения качества модели надо было дополнительно нормализовать значения и вектора, чтобы более обусловленно подходить к расстоянию между документами. Также можно было бы взять другие векторизаторы и сконкатенировать несколько эмбеддингов для улучшения качества и испольовать другие показатели схожести в модели, а не только расстояние между векторами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
